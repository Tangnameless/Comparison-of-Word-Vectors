{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.导入需要的工具包"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import random\r\n",
    "import logging\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "import torch\r\n",
    "import transformers as ppb\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "# set seed\r\n",
    "seed = 666\r\n",
    "random.seed(seed)\r\n",
    "np.random.seed(seed)\r\n",
    "torch.cuda.manual_seed(seed)\r\n",
    "torch.manual_seed(seed)\r\n",
    "\r\n",
    "# set cuda\r\n",
    "gpu = 0\r\n",
    "use_cuda = gpu >= 0 and torch.cuda.is_available()\r\n",
    "if use_cuda:\r\n",
    "    torch.cuda.set_device(gpu)\r\n",
    "    device = torch.device(\"cuda\", gpu)\r\n",
    "else:\r\n",
    "    device = torch.device(\"cpu\")\r\n",
    "logging.info(\"Use cuda: %s, gpu id: %d.\", use_cuda, gpu)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.载入数据"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv('./train.tsv', delimiter='\\t', header=None)\r\n",
    "# 为做示例只取前2000条数据\r\n",
    "batch_1 = df[:2000]\r\n",
    "# 查看正负例的数量\r\n",
    "batch_1[1].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.载入预训练模型"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# For DistilBERT:\r\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\r\n",
    "\r\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\r\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\r\n",
    "\r\n",
    "# Load pretrained model/tokenizer\r\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\r\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4.数据预处理"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 分词"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokenized = batch_1[0].apply((lambda x:tokenizer.encode(x, add_special_tokens = True)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2 padding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "max_len = 0\r\n",
    "for i in tokenized.values:\r\n",
    "    if len(i) > max_len:\r\n",
    "        max_len = len(i)\r\n",
    "padded = np.array([i + [0] * (max_len - len(i)) for i in tokenized.values])\r\n",
    "np.array(padded).shape\r\n",
    "# Masking\r\n",
    "# attention_mask（也就是input_mask）的0值只作用在padding部分\r\n",
    "# np.where(condition, x, y) 满足条件(condition)，输出x，不满足输出y\r\n",
    "attention_mask = np.where(padded != 0, 1, 0)\r\n",
    "attention_mask.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5.使用BERT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 基本可以看作又进行了一次embedding\r\n",
    "input_ids = torch.LongTensor(padded)\r\n",
    "attention_mask = torch.tensor(attention_mask)\r\n",
    "\r\n",
    "with torch.no_grad():\r\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "last_hidden_states[0].shape\r\n",
    "features = last_hidden_states[0][:,0,:].numpy()\r\n",
    "features.shape\r\n",
    "labels = batch_1[1] # 取出标签"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6.用机器学习的方法训练一个分类器"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.1划分训练集和测试集"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "parameters = {'C': np.linspace(0.0001, 100, 20)}\r\n",
    "grid_search = GridSearchCV(LogisticRegression(), parameters)\r\n",
    "grid_search.fit(train_features, train_labels)\r\n",
    "\r\n",
    "print('best parameters: ', grid_search.best_params_)\r\n",
    "print('best scrores: ', grid_search.best_score_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lr_clf = LogisticRegression(C = 10.526405263157894)\r\n",
    "lr_clf.fit(train_features, train_labels)\r\n",
    "lr_clf.score(test_features, test_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7.结果评估"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.dummy import DummyClassifier\r\n",
    "clf = DummyClassifier()\r\n",
    "\r\n",
    "scores = cross_val_score(clf, train_features, train_labels)\r\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8. 进行fine-tuning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91bd291942a2aa723212e0eb35859faec3dea88cc6ce7825ed8acaeab547d110"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('pytorch_gpu': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}